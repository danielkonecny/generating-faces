{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ffhq128x128_generate.ipynb","provenance":[],"collapsed_sections":["tW4AhF_d6lme","gsYZ35nkubgX","jbCygbO46zDC","9SP7eHX62NeZ","70EpoLdMVNVZ","uWXdfx_q5j_R","ugV1SEHUO13Q"],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"yTW77kXOHeB2","colab_type":"text"},"source":["# GAN - FFHQ - 128×128 px\n","Generative Adversarial Network for generating images of faces from Flickr-Faces-HQ database - code for generating images.\n","\n","Developed by Daniel Konečný"]},{"cell_type":"markdown","metadata":{"id":"tW4AhF_d6lme","colab_type":"text"},"source":["## Initialize\n","Defines the basic libraries and initializes global variables needed in all codes. Connects the code to data source - Google Drive."]},{"cell_type":"code","metadata":{"id":"FbIpx3KiXTJ9","colab_type":"code","colab":{}},"source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import imageio\n","import os\n","from tensorflow.keras.models import load_model\n","from PIL import Image, ImageDraw, ImageFont\n","from glob import glob\n","\n","dataset = 'ffhq'\n","x_dimension = 128\n","y_dimension = 128\n","note = ''\n","\n","project_name = f'{dataset}{x_dimension}x{y_dimension}{note}'\n","project_path = '/'\n","animation_path = f'{project_path}animations/'\n","image_path = f'{project_path}images/'\n","model_path = f'{project_path}models/'\n","weight_path = f'{project_path}weights/'\n","\n","latent_dimension = 256"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gsYZ35nkubgX","colab_type":"text"},"source":["## Generating functions\n","All functions necessary for generating, initialize before."]},{"cell_type":"code","metadata":{"id":"xxJqFTBwgT9Z","colab_type":"code","colab":{}},"source":["def get_latent_points(sample_count=1):\n","\tlatents = np.empty((sample_count, latent_dimension))\n","\n","\tfor latents_index in range(sample_count):\n","\t\trandoms = np.random.normal(0, 1, latent_dimension)\n","\t\tnormalizer = np.sum(randoms**2)**0.5\n","\t\tlatent = randoms/normalizer\n","\t\tlatents[latents_index] = latent\n","\t\n","\treturn latents\n","\n","\n","def get_images(epoch_number, latent_points):\n","    print(f'Creating images from epoch {epoch_number}...')\n","    model = load_model(f'{model_path}{project_name}_generator{epoch_number:04d}.h5',\n","                       compile=False)\n","    images = model.predict(latent_points)\n","    return images\n","\n","\n","def save_image(image_numpy, index, specifier=\"image\"):\n","    print('Saving image...')\n","    image_numpy = np.squeeze(image_numpy, axis=0)\n","    image_numpy *= 255.0\n","    image_numpy = image_numpy.astype('uint8')\n","    image_pil = Image.fromarray(image_numpy)\n","\n","    if specifier == \"animation\":\n","        image_pil = image_pil.convert('RGBA')\n","\n","        color = (255, 255, 255)\n","        transparency = 0.7\n","        opacity = int(255 * transparency)\n","        overlay = Image.new('RGBA', image_pil.size, color+(0,))\n","        draw = ImageDraw.Draw(overlay)\n","        draw.rectangle(((x_dimension-28, y_dimension-13),\n","                        (x_dimension-2, y_dimension-2)),\n","                       fill=color+(opacity,))\n","\n","        draw.text((x_dimension-27, y_dimension-14),\n","                  text=f'{index:04d}',\n","                  fill='black', font=font)\n","\n","        image_pil = Image.alpha_composite(image_pil, overlay)\n","        image_pil = image_pil.convert('RGB')\n","\n","    filename = f'{image_path}{project_name}_{specifier}{index:04d}.png'\n","    image_pil.save(filename)\n","\n","\n","def load_images(filename):\n","    print(\"Loading images...\")\n","    filenames = glob(filename)\n","    return sorted(filenames)\n","\n","\n","def create_animation(filenames):\n","    print(\"Creating animation...\")\n","    with imageio.get_writer(f'{animation_path}{project_name}_animation.gif',\n","                            mode='I') as writer:\n","        for i, filename in enumerate(filenames):\n","            image = imageio.imread(filename)\n","            writer.append_data(image)\n","        for i in range(20):\n","            image = imageio.imread(filename)\n","            writer.append_data(image)\n","\n","\n","def delete_images(filenames):\n","    print(\"Deleting images...\")\n","    for i, filename in enumerate(filenames):\n","        os.remove(filename)\n","\n","\n","def create_grid(images, image_grid_size):\n","\tprint(\"Creating image grid...\")\n","\tfor grid_index in range(image_grid_size * image_grid_size):\n","\t\tplt.subplot(image_grid_size, image_grid_size, 1 + grid_index)\n","\t\tplt.axis('off')\n","\t\tplt.imshow(images[grid_index, :, :, :])\n","\tplt.savefig(f'{image_path}{project_name}_grid.png',\n","                bbox_inches='tight', pad_inches=0.2, dpi=180)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jbCygbO46zDC","colab_type":"text"},"source":["## Create Generator Models\n","Create generator models from saved weights. Set number of already created epochs, number of done epochs with saved weights and launch."]},{"cell_type":"code","metadata":{"id":"-9lhjxbh6ysH","colab_type":"code","colab":{}},"source":["from tensorflow.keras import layers\n","\n","finished_epochs = 700\n","epoch_count = 700\n","\n","\n","def get_generator():\n","\tgenerator = tf.keras.Sequential()\n","\t\n","\tgenerator.add(layers.Dense(x_dimension//32 * y_dimension//32 * 256, input_dim=latent_dimension))\n","\tgenerator.add(layers.LeakyReLU(alpha=0.2))\n","\tgenerator.add(layers.Reshape((x_dimension//32, y_dimension//32, 256)))\n","\tassert generator.output_shape == (None, x_dimension//32, y_dimension//32, 256)\n","\n","\tgenerator.add(layers.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same'))\n","\tgenerator.add(layers.LeakyReLU(alpha=0.2))\n","\tassert generator.output_shape == (None, x_dimension//16, y_dimension//16, 256)\n","\n","\tgenerator.add(layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same'))\n","\tgenerator.add(layers.LeakyReLU(alpha=0.2))\n","\tassert generator.output_shape == (None, x_dimension//8, y_dimension//8, 128)\n","\n","\tgenerator.add(layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same'))\n","\tgenerator.add(layers.LeakyReLU(alpha=0.2))\n","\tassert generator.output_shape == (None, x_dimension//4, y_dimension//4, 128)\n"," \n","\tgenerator.add(layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same'))\n","\tgenerator.add(layers.LeakyReLU(alpha=0.2))\n","\tassert generator.output_shape == (None, x_dimension//2, y_dimension//2, 64)\n"," \n","\tgenerator.add(layers.Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same'))\n","\tgenerator.add(layers.LeakyReLU(alpha=0.2))\n","\tassert generator.output_shape == (None, x_dimension, y_dimension, 32)\n"," \n","\tgenerator.add(layers.Conv2D(3, (1, 1), activation='sigmoid', padding='same'))\n","\tassert generator.output_shape == (None, x_dimension, y_dimension, 3)\n","\n","\treturn generator\n","\n","\n","generator = get_generator()\n","\n","print(\"Creating generator models...\")\n","for epoch_index in range(finished_epochs, epoch_count):\n","    generator.load_weights(f'{weight_path}{project_name}_generator{epoch_index+1:04d}.h5')\n","    generator.save(f'{model_path}{project_name}_generator{epoch_index+1:04d}.h5')\n","    print(f'- Model {epoch_index+1} created.')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9SP7eHX62NeZ","colab_type":"text"},"source":["## Create a Set of Images\n","Set the epoch index of the used model, first index of generating, number of wanted images and launch for generating."]},{"cell_type":"code","metadata":{"id":"OPsArsgL2QPO","colab_type":"code","colab":{}},"source":["epoch_number = 700\n","first_index = 0\n","image_count = 50\n","\n","for image_index in range(first_index, first_index+image_count):\n","    latent_point = get_latent_points()\n","    image = get_images(epoch_number, latent_point)\n","    save_image(image, image_index)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"70EpoLdMVNVZ","colab_type":"text"},"source":["## Create Training Progress Animation\n","Creates animation showing the progress of training when given the same point in the latent space. Set the final epoch index of the model and launch.\n","\n","**Requires saved models that are not part of the submitted files because of their size. Therefore, it is necessary to train the network individually.**"]},{"cell_type":"code","metadata":{"id":"t9cePpdpYijK","colab_type":"code","colab":{}},"source":["epoch_count = 700\n","\n","latent_point = get_latent_points()\n","\n","for epoch_index in range(epoch_count):\n","    # First the animation goes slow for big steps in training,\n","    # then fast when the changes get smaller.\n","    if epoch_index < 50 or \\\n","        epoch_index < 200 and (epoch_index + 1) % 5 == 0 or \\\n","        epoch_index < 1000 and (epoch_index + 1) % 10 == 0 or \\\n","        (epoch_index + 1) % 50 == 0:\n","        image = get_images(epoch_index+1, latent_point)\n","        save_image(image, epoch_index+1, \"animation\")\n","\n","filenames = load_images(f'{image_path}{project_name}_animation*.png')\n","create_animation(filenames)\n","delete_images(filenames)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uWXdfx_q5j_R","colab_type":"text"},"source":["## Create Training Progress Images\n","Creates images from one latent and model but in different parts of training. Set the epoch indices of the model and launch.\n"]},{"cell_type":"code","metadata":{"id":"SvCwd4Cx5nTO","colab_type":"code","colab":{}},"source":["epoch_numbers = [10, 50, 100, 700]\n","\n","latent_point = get_latent_points()\n","\n","for epoch_index in epoch_numbers:\n","    image = get_images(epoch_index, latent_point)\n","    save_image(image, epoch_index, \"progress\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ugV1SEHUO13Q","colab_type":"text"},"source":["## Create a Grid of Final Images\n","Creates n×n grid of images generated from given epoch. Set the epoch index of the model, size of the square grid and launch."]},{"cell_type":"code","metadata":{"id":"WPAN2On8RQes","colab_type":"code","colab":{}},"source":["epoch_number = 700\n","image_grid_size = 3\n","\n","latent_points = get_latent_points(image_grid_size*image_grid_size)\n","images = get_images(epoch_number, latent_points)\n","create_grid(images, image_grid_size)"],"execution_count":0,"outputs":[]}]}